model,syntax_accuracy,accuracy_pct,norm,lmar_rank,lmar_name,mmlu_pct,mmlu_name
deepseek-v3.1,0.95,95.0,deepseekv31,19,deepseek-v3.1,87.2,DeepSeek v3
gemini-2.5-flash,1.0,100.0,gemini25flash,30,gemini-2.5-flash,73.9,Gemini 1.5 Flash (002)
gemini-2.5-flash-lite,0.88125,88.125,gemini25flashlite,30,gemini-2.5-flash,73.9,Gemini 1.5 Flash (002)
gemini-2.5-pro,0.99375,99.375,gemini25pro,5,gemini-2.5-pro,86.9,Gemini 1.5 Pro (002)
gemma-3-27b-it,0.69375,69.375,gemma327bit,74,gemma-3-27b-it,75.7,Gemma 2 (27B)
glm-4.6,0.98125,98.125,glm46,15,glm-4.6,,
gpt-oss-20b,0.9875,98.75,gptoss20b,114,gpt-oss-20b,84.3,GPT-4o (2024-08-06)
kimi-k2-instruct,0.95,95.0,kimik2instruct,241,phi-3-mini-4k-instruct,65.9,Jamba Instruct
llama-3.1-8b-instruct,0.6875,68.75,llama318binstruct,199,llama-3.1-8b-instruct,56.10000000000001,Llama 3.1 Instruct Turbo (8B)
llama-3.2-1b-instruct,0.53125,53.125,llama321binstruct,251,llama-3.2-1b-instruct,56.10000000000001,Llama 3.1 Instruct Turbo (8B)
llama-3.2-3b-instruct,0.625,62.5,llama323binstruct,217,llama-3.2-3b-instruct,79.10000000000001,Llama 3.3 Instruct Turbo (70B)
llama-3.3-70b-instruct,0.7,70.0,llama3370binstruct,117,llama-3.3-70b-instruct,79.10000000000001,Llama 3.3 Instruct Turbo (70B)
mixtral-8x22b-instruct,0.525,52.5,mixtral8x22binstruct,185,mixtral-8x22b-instruct-v0.1,77.8,Mixtral (8x22B)
qwen3-next-80b-a3b-instruct,0.7625,76.25,qwen3next80ba3binstruct,40,qwen3-next-80b-a3b-instruct,82.39999999999999,Qwen2 Instruct (72B)
qwen3-next-80b-a3b-thinking,0.84375,84.375,qwen3next80ba3bthinking,70,qwen3-next-80b-a3b-thinking,,
