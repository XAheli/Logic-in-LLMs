model,syllogism_accuracy,lmarena_rank,mmlu_score
deepseek-v3.1,0.9578125,19.0,0.872
gemini-2.5-flash,0.99375,30.0,
gemini-2.5-flash-lite,0.8796875,,
gemini-2.5-pro,0.9921875,5.0,0.869
gemma-3-27b-it,0.690625,74.0,0.757
glm-4.6,0.9875,15.0,
gpt-oss-20b,0.98125,114.0,
kimi-k2-instruct,0.9515625,18.0,
llama-3.1-8b-instruct,0.6390625,199.0,0.561
llama-3.2-1b-instruct,0.5421875,251.0,
llama-3.2-3b-instruct,0.6109375,217.0,
llama-3.3-70b-instruct,0.6890625,117.0,0.791
mixtral-8x22b-instruct,0.525,185.0,0.778
qwen3-next-80b-a3b-instruct,0.790625,40.0,
qwen3-next-80b-a3b-thinking,0.7234375,70.0,
