{
  "metadata": {
    "model": "llama-3.1-8b-instruct",
    "strategy": "zero_shot",
    "temperature": 0.5,
    "timestamp": "2025-12-02T16:38:42.325390"
  },
  "results": [
    {
      "syllogism_id": "SYL_001",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:12:27.169920",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:12:34.691385",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:12:42.036530",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:12:49.566970",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:12:57.000166",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:13:04.588456",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:13:12.042391",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:13:19.694553",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:13:26.989610",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:13:34.512201",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect.",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:13:49.548380",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 6,
      "incorrect_count": 4,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:14:04.628373",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:14:12.050727",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:14:19.751768",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:14:34.992483",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:14:42.205652",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:14:49.563857",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect.",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:14:57.129812",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:15:04.586063",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:15:12.045665",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:15:27.005062",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:15:34.521779",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect.",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:15:42.173177",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:15:49.533640",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:16:04.783785",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:16:19.584121",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:16:27.085679",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:16:34.684704",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:16:42.051100",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct.",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:16:49.704451",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:16:57.053224",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:17:04.561860",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:17:19.575508",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:17:27.019732",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:17:34.580418",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:17:42.083355",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:17:57.069213",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:18:04.595191",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:18:12.066736",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:18:27.011320",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:18:42.686911",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:18:49.517235",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:18:57.201955",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:19:04.520232",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:19:12.074556",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:19:19.602966",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:19:27.182882",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:19:34.602557",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:19:49.761857",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:20:04.610090",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:20:19.765868",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:20:34.613278",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 6,
      "incorrect_count": 4,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:20:49.600648",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:20:57.141699",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:21:12.296521",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:21:19.568472",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct.",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:21:27.134686",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:21:34.620497",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:21:42.066031",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:21:57.150113",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct.",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:22:12.123966",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:22:27.153891",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:22:34.620537",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:22:49.625083",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "Correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:22:57.361650",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:23:12.170697",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:23:27.084991",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:23:34.637945",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:23:42.191689",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:23:49.795106",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:23:57.111464",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:24:04.754245",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:24:12.070630",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:24:27.087328",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:24:34.747569",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:24:42.048446",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:24:49.752219",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:24:57.230947",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:25:04.769349",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:25:12.233118",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:25:19.698243",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:25:27.247150",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:25:34.644536",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:25:49.607870",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:25:57.133362",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:26:04.567442",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:26:12.093498",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:26:27.114712",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:26:34.722056",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:26:42.142010",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:26:49.634964",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:26:57.319397",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:27:04.735190",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:27:12.134989",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 6,
      "incorrect_count": 4,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:27:27.076802",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:27:34.626893",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:27:49.618459",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:27:57.250990",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:28:12.110759",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:28:19.622202",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:28:27.152033",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:28:42.137302",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:28:57.069393",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:29:04.855299",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:29:12.101227",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:29:27.157920",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:29:42.282706",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:29:49.899183",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:29:57.257967",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:30:04.813393",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:30:19.846186",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 6,
      "incorrect_count": 4,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:30:34.898685",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:30:42.353268",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:30:57.340687",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 6,
      "incorrect_count": 4,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:31:12.381491",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:31:27.449813",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:31:34.820208",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:31:42.441982",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:31:49.819943",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:32:05.014085",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:32:12.294280",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:32:19.769711",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:32:34.802490",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:32:42.248426",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:32:57.479309",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:33:04.948387",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:33:19.840385",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:33:27.470783",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:33:34.961528",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:33:42.504624",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:33:49.978236",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:34:04.928184",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:34:12.323272",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:34:19.850929",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:34:35.136751",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:34:49.925418",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:34:57.666618",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:35:04.859592",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:35:12.511278",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:35:19.803840",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:35:27.559022",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:35:42.314516",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:35:49.952767",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:35:57.504222",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:36:04.945074",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect.",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:36:12.269206",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:36:19.895968",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:36:34.846671",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:36:42.353410",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:36:49.874062",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:36:57.478479",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:37:04.797978",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:37:12.373337",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:37:27.379959",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:37:34.866338",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:37:49.893142",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "Correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T16:37:57.383997",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:38:12.437271",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:38:27.353199",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T16:38:42.325083",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    }
  ]
}