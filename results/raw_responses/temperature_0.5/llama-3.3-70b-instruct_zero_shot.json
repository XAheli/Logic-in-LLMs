{
  "metadata": {
    "model": "llama-3.3-70b-instruct",
    "strategy": "zero_shot",
    "temperature": 0.5,
    "timestamp": "2025-12-01T15:49:30.097692"
  },
  "results": [
    {
      "syllogism_id": "SYL_001",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:26:19.258938",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:26:26.395776",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:26:33.972360",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:26:41.351539",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:26:49.132479",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:26:56.315446",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:03.806330",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:11.564811",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:19.157140",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:26.332466",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:34.088373",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:41.586811",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:49.025159",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:27:56.324169",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:04.204789",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:11.526785",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:18.842321",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:26.825945",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:34.527317",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:41.726043",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:49.271664",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:28:56.716983",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:29:04.082943",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:29:11.854201",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:29:32.060884",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:29:39.122060",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:29:46.403149",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:29:54.052107",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:01.653725",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:08.912303",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:16.408598",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:24.078225",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:31.657292",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:39.439778",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:46.565369",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:30:53.948601",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:31:06.804395",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:31:14.342083",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:31:29.540078",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:31:37.167134",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:31:44.623927",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:31:52.466127",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:31:59.839156",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:32:07.190376",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:32:15.556851",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:32:22.829315",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:32:30.239994",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:32:37.714647",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:32:45.818382",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:32:52.840924",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:33:00.652831",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:33:08.108642",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:33:24.129198",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:33:39.257866",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:33:46.528248",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:34:01.558288",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:34:16.677180",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:34:24.071341",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:34:31.687609",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:34:39.266741",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:34:54.216073",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:35:22.644117",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:35:30.364209",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:35:37.424324",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:35:45.151021",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:35:52.574363",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:00.272099",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:07.640182",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:15.218132",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:22.526651",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:30.066120",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:37.615790",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:46.684533",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:36:53.618827",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:01.317612",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:08.544858",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:16.204020",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:23.897728",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:31.191460",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:38.537827",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:46.151388",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:37:53.769161",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:01.104596",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:08.341045",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:16.157286",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:23.446169",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:32.232697",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:39.530612",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:47.367099",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:38:54.921579",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:39:02.339457",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:39:09.774944",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:39:17.193803",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:39:24.677339",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:39:39.800246",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:39:54.532384",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:02.449680",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:10.219634",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:17.279330",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:24.791146",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:32.556371",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:39.704857",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:47.406687",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:40:55.075464",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:02.152786",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:09.635023",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:17.614582",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:24.896096",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:32.512375",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:39.815078",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:47.310791",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:41:54.811342",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:02.158149",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:09.961461",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:17.316623",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:24.956912",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:32.087689",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:39.955482",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:47.420288",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:42:55.166754",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:02.072216",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:09.956784",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:17.420091",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:24.698019",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:32.464932",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:40.015385",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:47.429494",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:43:54.939615",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:02.323558",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:10.049731",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:17.638882",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:24.663131",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:32.691367",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:39.911445",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:47.641755",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:44:54.742191",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:02.537909",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:10.067790",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:17.420158",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:24.806311",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:32.595527",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:40.052345",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:47.240809",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:45:54.830547",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:02.702673",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:09.864069",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:17.449226",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:24.798987",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:32.501959",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:39.851805",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:47.555895",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:46:54.950538",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:47:02.710968",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 0,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-01T15:48:44.307426",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!",
          "vote": "unclear"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:48:52.282528",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:48:59.655927",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:49:07.744817",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:49:15.220835",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:49:22.800296",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "zero_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T15:49:30.097419",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    }
  ]
}