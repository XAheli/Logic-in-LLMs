{
  "metadata": {
    "model": "llama-3.1-8b-instruct",
    "strategy": "one_shot",
    "temperature": 0.5,
    "timestamp": "2025-12-02T17:39:52.038336"
  },
  "results": [
    {
      "syllogism_id": "SYL_001",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:14:29.413217",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:14:36.771390",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:14:44.387226",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:14:51.761125",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:14:59.417991",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:15:06.892584",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:15:14.368826",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:15:21.946573",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:15:29.325761",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:15:36.879026",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:15:44.351434",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:15:59.467648",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:06.998379",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:14.487444",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:21.854686",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:29.273562",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:37.007921",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:44.494197",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:51.976160",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:16:59.283395",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:17:14.480015",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:17:29.536881",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:17:36.844284",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:17:44.416196",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:17:51.861338",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:17:59.485140",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:18:06.889276",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:18:14.345445",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:18:21.878412",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:18:29.329931",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:18:44.391953",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:18:51.865627",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:18:59.340702",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:19:07.123185",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:19:14.403165",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:19:29.471783",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:19:44.319794",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:19:51.807291",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:19:59.406641",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:20:07.026597",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:20:21.977909",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:20:36.883522",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:20:44.507756",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:20:51.888003",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:20:59.381013",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:21:06.891809",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:21:21.900573",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:21:29.379068",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:21:36.934746",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:21:51.987147",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:21:59.462769",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:22:14.364963",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:22:29.463114",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:22:37.280617",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:22:51.915720",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:22:59.474005",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:23:06.887865",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 6,
      "incorrect_count": 4,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:23:21.933916",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:23:36.875233",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:23:52.028866",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:23:59.412528",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:24:14.414590",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:24:21.928606",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:24:36.933898",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:24:51.851069",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:24:59.558145",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:25:14.423814",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:25:29.998046",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:25:36.925467",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:25:44.492243",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:25:52.018474",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:25:59.436168",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:26:06.929105",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:26:14.543122",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:26:22.017978",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:26:29.425238",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:26:36.968818",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:26:44.461810",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:26:59.598378",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:27:06.962029",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:27:14.365066",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:27:22.128573",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:27:37.181217",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:27:52.028563",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:27:59.526128",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:28:06.953982",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:28:14.491338",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:28:21.894857",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:28:29.486113",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:28:37.085071",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:28:52.102579",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:28:59.467783",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:29:07.090895",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:29:21.965082",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:29:36.960044",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:29:52.045810",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:29:59.722776",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:30:14.458623",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:30:22.148809",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:30:29.522630",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:30:36.998063",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:30:44.521603",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:30:59.526375",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:31:14.627514",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:31:21.928792",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:31:29.529281",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:31:37.014634",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:31:52.058174",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:31:59.550383",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:32:14.569494",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:32:29.544996",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:32:37.074544",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:32:44.487495",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:32:52.068814",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:32:59.470772",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:33:14.507700",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:33:22.070022",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:33:29.425229",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:33:37.156029",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:33:44.597776",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:33:51.954069",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:33:59.548020",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:34:14.518346",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:34:22.077505",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:34:29.654754",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:34:36.993605",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 4,
      "incorrect_count": 6,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:34:52.081826",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:34:59.492173",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:35:06.963790",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:35:14.458514",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:35:21.998324",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:35:29.560024",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:35:37.133260",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:35:44.612949",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:35:52.191072",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:36:07.017888",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:36:14.535930",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "Incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:36:22.296422",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:36:29.567841",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:36:37.112802",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect.",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:36:44.550427",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:36:52.096290",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:36:59.626085",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:37:14.486917",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:37:22.211401",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:37:29.483136",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:37:44.774208",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:37:59.549313",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:38:07.043488",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:38:14.632363",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:38:29.547373",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:38:37.060074",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:38:44.739755",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:38:52.319398",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:38:59.755966",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:39:14.680369",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "N",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:39:22.119175",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "O",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-02T17:39:37.169162",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "X",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:39:44.646109",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "OX",
      "model_key": "llama-3.1-8b-instruct",
      "temperature": 0.5,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-02T17:39:52.038043",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "Incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    }
  ]
}