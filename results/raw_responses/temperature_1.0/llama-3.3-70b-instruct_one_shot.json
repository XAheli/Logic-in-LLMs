{
  "metadata": {
    "model": "llama-3.3-70b-instruct",
    "strategy": "one_shot",
    "temperature": 1.0,
    "timestamp": "2025-12-01T17:01:57.658536"
  },
  "results": [
    {
      "syllogism_id": "SYL_001",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:38:52.756497",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:00.356130",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:08.253057",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:15.409680",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:22.968401",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:30.458033",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:38.004296",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:45.031244",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:39:52.888949",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:40:00.267405",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:40:07.821651",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:40:15.315522",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:40:22.933161",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:40:30.368152",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:40:38.049596",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.8,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 2,
      "incorrect_count": 8,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:40:54.544409",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:02.025499",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:09.997782",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:17.026840",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:24.659228",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:31.909768",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:39.545574",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:47.178218",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:41:54.522745",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:02.016569",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:09.541872",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:17.026930",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:29.440733",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:37.245733",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:44.636140",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:52.634090",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:42:59.697631",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:43:06.941437",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:43:14.290648",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:43:21.826077",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:43:40.718084",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:43:48.047876",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:43:55.558922",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:44:03.388001",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:44:10.572059",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:44:41.619550",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:44:48.811524",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:44:56.202533",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:45:11.471691",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.7,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 7,
      "incorrect_count": 3,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:45:26.605720",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.8,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 8,
      "incorrect_count": 2,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:45:41.610221",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:45:48.841737",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:46:03.792266",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:46:18.735560",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:46:26.695720",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:46:41.891218",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:46:49.362809",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:46:56.940149",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:47:04.288406",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:47:16.555896",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:47:23.390195",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:47:32.887874",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:47:39.899234",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:47:54.550658",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:48:13.561137",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:48:28.594582",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:48:36.988998",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:48:44.355187",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:48:51.966075",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:48:59.618066",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:49:07.105659",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:49:14.680788",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:49:22.197512",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:49:29.484804",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:49:37.020098",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.9,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 1,
      "incorrect_count": 9,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:49:52.248685",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:49:59.856275",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:50:07.302936",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:50:14.927524",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.7,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 3,
      "incorrect_count": 7,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:50:29.864434",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:50:37.156594",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:50:44.684371",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:50:52.261937",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:51:00.017230",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:51:14.995833",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:51:22.449121",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:51:29.895761",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:51:37.626335",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:51:45.128215",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:51:52.576999",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:51:59.687334",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:52:15.099821",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 0.5,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 10,
      "correct_count": 5,
      "incorrect_count": 5,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:52:29.917163",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 9,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 10,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:52:37.224219",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:52:45.132114",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.6,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 6,
      "incorrect_count": 4,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:53:00.260178",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 0.9,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 10,
      "correct_count": 9,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T16:53:15.138276",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 6,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 7,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 8,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 9,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 10,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:53:22.321382",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:53:30.023206",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:53:37.538080",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 5,
      "incorrect_count": 0,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:53:44.817738",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 2,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 3,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 4,
          "response": "correct",
          "vote": "correct"
        },
        {
          "iteration": 5,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:53:52.592701",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:00.054668",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:07.571768",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:15.059830",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:22.557569",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:29.965106",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:41.637198",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:49.326005",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:54:56.512273",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:03.760513",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:11.268115",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:19.124672",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:26.490855",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:33.783822",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:42.144547",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:48.766520",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:55:56.286731",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:04.007849",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:11.553229",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:19.252342",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:26.513870",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:34.280866",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:41.303556",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:49.030503",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:56:56.739788",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:04.056375",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:11.759660",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:19.156507",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:26.301062",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:34.386913",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:41.674722",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:48.834188",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:57:56.721661",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:04.015648",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:11.647988",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:19.059806",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:26.625445",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:34.195473",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:41.761382",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:48.820854",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:58:56.678548",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:04.041314",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:11.781493",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:19.170788",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:26.733185",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:33.942542",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:41.763204",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:48.896586",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T16:59:56.328350",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:03.959045",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:11.683503",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:19.060780",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:26.558228",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:34.156473",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:41.818129",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:49.221337",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:00:56.643441",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:01:04.409998",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:01:11.770245",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:01:27.651993",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:01:35.143467",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:01:42.683509",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:01:50.423304",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 1.0,
      "prompting_strategy": "one_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 5,
      "correct_count": 0,
      "incorrect_count": 5,
      "stopped_early": true,
      "timestamp": "2025-12-01T17:01:57.658294",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 2,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 3,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 4,
          "response": "incorrect",
          "vote": "incorrect"
        },
        {
          "iteration": 5,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    }
  ]
}