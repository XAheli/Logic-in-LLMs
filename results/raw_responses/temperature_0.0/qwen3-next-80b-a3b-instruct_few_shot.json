{
  "metadata": {
    "model": "qwen3-next-80b-a3b-instruct",
    "strategy": "few_shot",
    "temperature": 0.0,
    "timestamp": "2025-12-01T18:10:01.323960"
  },
  "results": [
    {
      "syllogism_id": "SYL_001",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:05:59.768494",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:03.994997",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:06.262775",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:06.972268",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:08.482836",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:10.075018",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:12.003854",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:13.014242",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:14.495470",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:16.203395",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:17.534303",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:19.003515",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:20.475528",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:22.142054",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:23.576581",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:24.969388",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:26.449451",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:27.986841",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:29.526112",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:31.265595",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:32.445384",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:34.080748",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:35.557887",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:36.998729",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:38.527299",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:39.974678",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:41.452802",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:42.988346",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:44.497877",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:45.991749",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:47.451846",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:49.177214",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:50.470613",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:52.556620",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:53.577415",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:54.965964",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:56.550525",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:58.055714",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:06:59.520296",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:01.004656",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:02.555371",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:04.002860",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:05.584917",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:06.974564",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:08.467884",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:09.998313",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:11.467077",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:12.993676",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:14.505383",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:15.985990",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:17.484648",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:19.018130",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:20.517118",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:22.468418",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:23.456152",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:24.981148",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:27.014771",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:29.012583",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:29.685372",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:31.258145",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:32.902685",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:34.215353",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:35.771092",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:37.230440",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:38.739894",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:40.277877",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:41.730003",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:43.347360",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:44.706080",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:46.246851",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:47.853123",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:49.286488",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:50.737730",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:52.359700",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:53.720704",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:55.379729",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:56.762605",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:58.298683",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:07:59.867743",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:01.267882",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:02.772066",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:04.259350",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:05.783870",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:07.229346",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:08.803605",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:10.212514",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:11.713776",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:13.251948",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:14.785002",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:16.313458",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:17.770495",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:19.317377",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:20.752923",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:22.244998",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:23.797676",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:25.272554",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:26.744049",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:28.300667",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:29.714790",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:31.375369",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:32.801219",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:34.276496",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:35.766873",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:37.218955",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:38.736534",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:40.227189",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:41.699184",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:43.264961",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:44.790123",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:46.268909",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:47.793118",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:49.294671",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:50.764700",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:52.366960",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:53.800957",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:55.320356",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:56.741473",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:58.306963",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:08:59.756347",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:01.251599",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:02.813303",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:04.347679",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:05.722471",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:07.220579",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:08.735877",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:10.312425",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:11.822602",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:13.234552",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:14.896329",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:16.285753",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:17.870055",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:19.298493",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:20.776782",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:22.237167",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:23.821723",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:25.287393",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:26.882119",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:28.204113",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:29.776865",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:31.350284",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:32.725641",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:34.317601",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:35.752809",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:37.258236",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:38.840294",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:40.291180",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:41.722748",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:43.235184",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:44.763128",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:46.301819",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:47.767377",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:49.259308",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:50.747235",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:52.272732",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:53.708007",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:55.258391",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "N",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:56.842403",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "O",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:58.341214",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "X",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:09:59.746377",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "OX",
      "model_key": "qwen3-next-80b-a3b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T18:10:01.323750",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    }
  ]
}