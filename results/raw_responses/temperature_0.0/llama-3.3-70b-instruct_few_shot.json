{
  "metadata": {
    "model": "llama-3.3-70b-instruct",
    "strategy": "few_shot",
    "temperature": 0.0,
    "timestamp": "2025-12-01T17:06:00.377377"
  },
  "results": [
    {
      "syllogism_id": "SYL_001",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:01:59.284331",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:00.641508",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:02.161124",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_001",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:03.675329",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:05.237598",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:06.743629",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:08.148004",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_002",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:09.665778",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:11.143553",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:12.626311",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:14.251572",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_003",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:15.657138",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:17.132103",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:18.666033",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:20.118548",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_004",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:21.638553",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:23.127209",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:24.650632",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:26.274133",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_005",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:27.634351",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:29.415759",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:30.648931",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:32.164488",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_006",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:33.662471",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:34.944290",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:36.623489",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:39.558792",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_007",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:40.256781",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:41.927955",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:43.464725",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:44.706337",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_008",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:46.206544",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:47.948007",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:49.511139",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:51.048818",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_009",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:52.555329",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:54.072544",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:55.571357",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:56.973327",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_010",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:58.602264",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:02:59.834068",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:01.677592",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:03.118513",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_011",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:04.235938",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:05.920659",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:07.424196",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:09.084617",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_012",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:10.768758",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:12.054588",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:13.385093",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:14.888131",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_013",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:16.451882",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:17.959165",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:19.504691",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:20.982292",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_014",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:22.427836",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:23.854593",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:25.449698",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:26.832665",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_015",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:28.758233",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:29.878243",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:31.477009",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:32.902014",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_016",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:34.487855",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:36.084680",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:37.415656",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:39.078763",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_017",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:40.540493",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:42.101844",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:43.659422",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:44.954842",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_018",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:46.939202",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:47.960952",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:49.578305",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:50.925078",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_019",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:52.600976",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:53.981132",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:55.585040",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:56.874194",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_020",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:03:58.570748",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:00.127759",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:01.581703",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:02.812508",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_021",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:04.252421",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:05.938985",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:07.665997",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:09.057761",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_022",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:10.587616",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:11.976245",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:13.393484",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:14.981959",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_023",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:16.534818",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:17.744902",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:19.562742",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:20.976120",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_024",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "valid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:22.451764",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:24.111368",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:25.520102",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:26.930820",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_025",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:28.580571",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:30.256146",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:31.425627",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:32.918214",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_026",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:34.361764",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:36.113736",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:39.652410",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:40.393748",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_027",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:42.175979",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:43.456777",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:44.796164",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:47.049498",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_028",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:48.017873",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:49.519804",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:50.804807",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:52.763713",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_029",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:54.065805",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:55.538411",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:56.980195",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:58.524512",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_030",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:04:59.811576",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:01.517792",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:02.818945",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:04.578661",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_031",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:06.029346",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:07.542390",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "believable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:08.847927",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:10.750798",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_032",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:12.487165",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:13.752978",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:15.516729",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:16.337421",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_033",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:18.432795",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:19.715391",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:21.167776",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:22.378932",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_034",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:24.199394",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:25.512598",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:27.194420",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:28.555353",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_035",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:30.023566",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:31.457493",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:33.057011",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:34.688143",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_036",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:36.038366",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:37.430872",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:39.185831",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:40.540900",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_037",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:41.846750",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:43.524027",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:45.068496",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:46.660749",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_038",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:47.829936",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:49.412836",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:50.806793",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:52.382016",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_039",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:54.029103",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "N",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:55.690465",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "O",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:56.890290",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "X",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "correct",
      "confidence": 1.0,
      "is_correct_syntax": false,
      "is_correct_NLU": false,
      "total_iterations": 1,
      "correct_count": 1,
      "incorrect_count": 0,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:05:59.422063",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "correct",
          "vote": "correct"
        }
      ]
    },
    {
      "syllogism_id": "SYL_040",
      "variant": "OX",
      "model_key": "llama-3.3-70b-instruct",
      "temperature": 0.0,
      "prompting_strategy": "few_shot",
      "ground_truth_syntax": "invalid",
      "ground_truth_NLU": "unbelievable",
      "predicted": "incorrect",
      "confidence": 1.0,
      "is_correct_syntax": true,
      "is_correct_NLU": true,
      "total_iterations": 1,
      "correct_count": 0,
      "incorrect_count": 1,
      "stopped_early": false,
      "timestamp": "2025-12-01T17:06:00.377138",
      "raw_responses": [
        {
          "iteration": 1,
          "response": "incorrect",
          "vote": "incorrect"
        }
      ]
    }
  ]
}